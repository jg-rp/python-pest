{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python Pest","text":"<p>Python Pest is a port of the Rust Pest parsing library - a powerful, elegant PEG (Parsing Expression Grammar) parser generator. We use exactly the same grammar syntax as Pest v2, so existing Pest grammars can be used without modification.</p>"},{"location":"#install","title":"Install","text":"<p>Use <code>pip</code> or your favorite package manager.</p> <pre><code>python -m pip install python-pest\n</code></pre>"},{"location":"#example","title":"Example","text":"<p>Let's say we want to parse input like:</p> <pre><code>[1, 2, 3, 42]\n</code></pre> <p>Our grammar is just a Python string, possibly read from a file (reading from a file means we don't need to worry about double escaping):</p> <pre><code>array      = { \"[\" ~ int_list ~ \"]\" }\nint_list   = { int ~ (\",\" ~ int)* }\nint        = @{ \"0\" | ASCII_NONZERO_DIGIT  ~ ASCII_DIGIT* }\nWHITESPACE = _{ \" \" }\n</code></pre> <p><code>array</code>, <code>int_list</code>, <code>int</code> and <code>WHITESPACE</code> are rules. A rule can reference other rules by name. <code>~</code> means followed by and <code>|</code> is ordered choice.</p> <p>To use a Pest grammar in Python we pass it to the static method <code>Parser.from_grammar()</code>, which returns a new instance of <code>Parser</code>.</p> <pre><code>from pest import Pair\nfrom pest import Parser\n\n# Read grammar rules from a file.\nwith open(\"example.pest\", encoding=\"utf-8\") as fd:\n    grammar = fd.read()\n\nparser = Parser.from_grammar(grammar)\n</code></pre> <p>Instances of <code>Parser</code> have a <code>parse()</code> method that takes the name of the rule to start parsing from and the input text to parse. Here we parse our example input and dump a compact representation of the resulting parse tree.</p> <pre><code># ... continued\nparse_tree = parser.parse(\"array\", \"[1, 2, 3, 42]\")\n\nprint(parse_tree.dumps())\n# - array &gt; int_list\n#   - int: \"1\"\n#   - int: \"2\"\n#   - int: \"3\"\n#   - int: \"42\"\n</code></pre> Debug output <p>A more detailed parse tree representation is available by passing <code>compact=False</code> to <code>Pairs.dumps()</code>.</p> <pre><code>print(parse_tree.dumps(compact=False))\n</code></pre> <pre><code>[\n  {\n    \"rule\": \"array\",\n    \"span\": {\n      \"str\": \"[1, 2, 3, 42]\",\n      \"start\": 0,\n      \"end\": 13\n    },\n    \"inner\": [\n      {\n        \"rule\": \"int_list\",\n        \"span\": {\n          \"str\": \"1, 2, 3, 42\",\n          \"start\": 1,\n          \"end\": 12\n        },\n        \"inner\": [\n          {\n            \"rule\": \"int\",\n            \"span\": {\n              \"str\": \"1\",\n              \"start\": 1,\n              \"end\": 2\n            },\n            \"inner\": []\n          },\n          {\n            \"rule\": \"int\",\n            \"span\": {\n              \"str\": \"2\",\n              \"start\": 4,\n              \"end\": 5\n            },\n            \"inner\": []\n          },\n          {\n            \"rule\": \"int\",\n            \"span\": {\n              \"str\": \"3\",\n              \"start\": 7,\n              \"end\": 8\n            },\n            \"inner\": []\n          },\n          {\n            \"rule\": \"int\",\n            \"span\": {\n              \"str\": \"42\",\n              \"start\": 10,\n              \"end\": 12\n            },\n            \"inner\": []\n          }\n        ]\n      }\n    ]\n  }\n]\n</code></pre> <p>A parse tree is composed of token <code>Pair</code> and <code>Pairs</code> types, where each node represents a matched grammar rule and all descendant rules. To make traversing and transforming that tree expressive and type-safe, we recommend using Python's structural pattern matching (<code>match</code>/<code>case</code>) syntax. It lets you destructure parse tree nodes directly by rule name and inner content, clearly showing what each branch of your parser expects.</p> <p>For this very simple example, we need just one match expression to match the <code>array</code> token pair and unpack its inner <code>int_list</code>.</p> <pre><code># ... continued\nmatch parse_tree.first():\n    case Pair(\"array\", [Pair(\"int_list\", inner)]):\n        numbers = [int(p.text) for p in inner]\n    case _:\n        raise ValueError(\"unexpected parse tree\")\n\nprint(numbers)\n</code></pre>"},{"location":"#code-generation","title":"Code generation","text":"<p>So far we've parsed input text directly from a grammar tree (the <code>Parser</code> instance), but you can also generate a Python module with <code>Parser.generate()</code>. This is something you'd do once after modifying your grammar.</p> <p>TODO: Show how to do this with the CLI - once I've written it.</p> <pre><code># ... continued\nwith open(\"parser.py\", \"w\", encoding=\"utf-8\") as fd:\n    fd.write(parser.generate())\n</code></pre> <p>Generated parser modules expose a <code>parse()</code> function, a <code>Rule</code> enum and a simple command line interface for testing your generated parser manually.</p> <p>Important</p> <p>This example is not continued from above. We are importing from the <code>parser.py</code> module we've just generated.</p> <pre><code>from parser import Rule\nfrom parser import parse\nfrom pest import Pair\n\nparse_tree = parse(Rule.ARRAY, \"[1, 2, 3, 42]\")\n\nmatch parse_tree.first():\n    case Pair(Rule.ARRAY, [Pair(Rule.INT_LIST, inner)]):\n        numbers = [int(p.text) for p in inner]\n    case _:\n        raise ValueError(\"unexpected parse tree\")\n\nprint(numbers)\n</code></pre> <p>Parse trees obtained from generated code are identical to those returned by <code>Parser.parse()</code>.</p>"},{"location":"#more-examples","title":"More examples","text":"<p>More involved and realistic examples can be found in the <code>examples/</code> folder in the root of this projects source tree.</p> <p><code>examples/jsonpath</code> is an implementation of RFC 9535 that uses the precedence climbing technique to handle operator precedence. You can compare it directly to python-jsonpath-rfc9535, which is implemented with a hand-crafted parser and identical internal representation.</p> <p><code>examples/calculator</code> shows three different approaches to handling operator precedence:</p> <ul> <li><code>examples/calculator/prec_climber.py</code> - Precedence climbing method,</li> <li><code>examples/calculator/pratt.py</code> - Pratt parsing (this one is the most readable),</li> <li><code>examples/calculator/grammar_encoded_prec.py</code> - precedence encoded directly in the grammar.</li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#pest.Parser","title":"pest.Parser","text":"<p>A pest parser.</p> <p>This class provides methods to parse text using a pest grammar, generate parser source code, and inspect the grammar tree.</p> PARAMETER DESCRIPTION <code>rules</code> <p>Mapping of rule names to <code>Rule</code> objects.</p> <p> TYPE: <code>Mapping[str, Rule]</code> </p> <code>doc</code> <p>Optional list of grammar documentation lines.</p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> <code>optimizer</code> <p>Optional optimizer to apply to the rules.</p> <p> TYPE: <code>Optimizer | None</code> DEFAULT: <code>None</code> </p> <code>debug</code> <p>If True, enables debug output during optimization.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> ATTRIBUTE DESCRIPTION <code>rules</code> <p>A mapping of rule names to <code>Rule</code> instances, including built-ins.</p> <p> TYPE: <code>dict[str, Rule]</code> </p> <code>doc</code> <p>An optional list of grammar documentation lines.</p> <p> </p>"},{"location":"api/#pest.Parser.from_grammar","title":"from_grammar  <code>classmethod</code>","text":"<pre><code>from_grammar(\n    grammar: str,\n    *,\n    optimizer: Optimizer | None = DEFAULT_OPTIMIZER,\n    debug: bool = False,\n) -&gt; Parser\n</code></pre> <p>Parse a grammar definition and return a new <code>Parser</code> for it.</p> PARAMETER DESCRIPTION <code>grammar</code> <p>The grammar definition as a string.</p> <p> TYPE: <code>str</code> </p> <code>optimizer</code> <p>Optional optimizer to apply to the rules.</p> <p> TYPE: <code>Optimizer | None</code> DEFAULT: <code>DEFAULT_OPTIMIZER</code> </p> <code>debug</code> <p>If True, enables debug output during optimization.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Parser</code> <p>A new parser instance for the given grammar.</p> <p> TYPE: <code>Parser</code> </p> RAISES DESCRIPTION <code>PestGrammarSyntaxError</code> <p>If <code>grammar</code> is invalid.</p>"},{"location":"api/#pest.Parser.generate","title":"generate","text":"<pre><code>generate() -&gt; str\n</code></pre> <p>Return a generated parser as Python module source code.</p> RETURNS DESCRIPTION <code>str</code> <p>The generated Python source code for the parser.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/#pest.Parser.parse","title":"parse","text":"<pre><code>parse(\n    start_rule: str, text: str, *, start_pos: int = 0\n) -&gt; Pairs\n</code></pre> <p>Parse <code>text</code> starting from the specified <code>start_rule</code>.</p> PARAMETER DESCRIPTION <code>start_rule</code> <p>The name of the rule to start parsing from.</p> <p> TYPE: <code>str</code> </p> <code>text</code> <p>The input string to parse.</p> <p> TYPE: <code>str</code> </p> <code>start_pos</code> <p>The position in the input string to start parsing from (default: 0).</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> RETURNS DESCRIPTION <code>Pairs</code> <p>The parse tree as a <code>Pairs</code> object.</p> <p> TYPE: <code>Pairs</code> </p> RAISES DESCRIPTION <code>KeyError</code> <p>If <code>start_rule</code> is not a valid rule name.</p> <code>PestParsingError</code> <p>If the input <code>text</code> cannot be parsed according to the grammar.</p>"},{"location":"api/#pest.Parser.tree_view","title":"tree_view","text":"<pre><code>tree_view() -&gt; str\n</code></pre> <p>Return a tree view for each non-built-in rule in this grammar.</p> RETURNS DESCRIPTION <code>str</code> <p>A string representation of the grammar's rule tree.</p> <p> TYPE: <code>str</code> </p>"},{"location":"api/#pest.Pair","title":"pest.Pair","text":"<p>A matching pair of Tokens and everything between them.</p> <p>Represents a node in the parse tree, corresponding to a matched rule and its children.</p> PARAMETER DESCRIPTION <code>input_</code> <p>The input string.</p> <p> TYPE: <code>str</code> </p> <code>start</code> <p>Start position in the input.</p> <p> TYPE: <code>int</code> </p> <code>end</code> <p>End position in the input.</p> <p> TYPE: <code>int</code> </p> <code>rule</code> <p>The rule or rule frame this pair represents.</p> <p> TYPE: <code>Rule | RuleFrame</code> </p> <code>children</code> <p>List of child pairs (subrules).</p> <p> TYPE: <code>list[Pair] | None</code> DEFAULT: <code>None</code> </p> <code>tag</code> <p>Optional tag for this node.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p>"},{"location":"api/#pest.Pair.inner_texts","title":"inner_texts  <code>property</code>","text":"<pre><code>inner_texts: list[str]\n</code></pre> <p>The list of substrings pointed to by this pair's children.</p>"},{"location":"api/#pest.Pair.text","title":"text  <code>property</code>","text":"<pre><code>text: str\n</code></pre> <p>The substring pointed to by this token pair.</p>"},{"location":"api/#pest.Pair.as_str","title":"as_str","text":"<pre><code>as_str() -&gt; str\n</code></pre> <p>Return the substring pointed to by this token pair.</p>"},{"location":"api/#pest.Pair.dump","title":"dump","text":"<pre><code>dump() -&gt; dict[str, object]\n</code></pre> <p>Return a pest-debug-like JSON structure representing this pair.</p>"},{"location":"api/#pest.Pair.dumps","title":"dumps","text":"<pre><code>dumps(indent: int = 0, *, new_line: bool = True) -&gt; str\n</code></pre> <p>Return a string representation of this token pair and all its children.</p> <p>Translated from the <code>format_pair</code> function found in the source for pest.rs.</p> <p>https://github.com/pest-parser/site/blob/master/src/lib.rs.</p>"},{"location":"api/#pest.Pair.inner","title":"inner","text":"<pre><code>inner() -&gt; Pairs\n</code></pre> <p>Return inner pairs between this token pair.</p>"},{"location":"api/#pest.Pair.line_col","title":"line_col","text":"<pre><code>line_col() -&gt; tuple[int, int]\n</code></pre> <p>Return the line and column number of this pair's start position.</p>"},{"location":"api/#pest.Pair.span","title":"span","text":"<pre><code>span() -&gt; Span\n</code></pre> <p>Return the (start, end) span of this node.</p>"},{"location":"api/#pest.Pair.stream","title":"stream","text":"<pre><code>stream() -&gt; Stream\n</code></pre> <p>Return inner pairs as a stream.</p>"},{"location":"api/#pest.Pair.tokens","title":"tokens","text":"<pre><code>tokens() -&gt; Iterator[Token]\n</code></pre> <p>Yield start and end tokens for this pair and any children in between.</p>"},{"location":"api/#pest.Pairs","title":"pest.Pairs","text":"<p>               Bases: <code>Sequence[Pair]</code></p> <p>A sequence of token pairs.</p> <p>Provides sequence and utility methods for working with lists of Pair objects.</p> PARAMETER DESCRIPTION <code>pairs</code> <p>List of Pair objects.</p> <p> TYPE: <code>list[Pair]</code> </p>"},{"location":"api/#pest.Pairs.dump","title":"dump","text":"<pre><code>dump() -&gt; list[dict[str, object]]\n</code></pre> <p>Return pairs as a JSON-like list of dicts.</p>"},{"location":"api/#pest.Pairs.dumps","title":"dumps","text":"<pre><code>dumps(*, compact: bool = True) -&gt; str\n</code></pre> <p>Return a JSON formatted string representation of this node.</p> PARAMETER DESCRIPTION <code>compact</code> <p>If True, returns a compact string; otherwise, pretty-prints JSON.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string representation of the pairs.</p>"},{"location":"api/#pest.Pairs.find_first_tagged","title":"find_first_tagged","text":"<pre><code>find_first_tagged(label: str) -&gt; Pair | None\n</code></pre> <p>Finds the first pair that has its node tagged with <code>label</code>.</p> PARAMETER DESCRIPTION <code>label</code> <p>The tag to search for.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Pair | None</code> <p>The first Pair with the given tag, or None if not found.</p>"},{"location":"api/#pest.Pairs.find_tagged","title":"find_tagged","text":"<pre><code>find_tagged(label: str) -&gt; Iterator[Pair]\n</code></pre> <p>Iterate over pairs tagged with <code>label</code>.</p> PARAMETER DESCRIPTION <code>label</code> <p>The tag to search for.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>Iterator[Pair]</code> <p>An iterator over all Pairs with the given tag.</p>"},{"location":"api/#pest.Pairs.first","title":"first","text":"<pre><code>first() -&gt; Pair\n</code></pre> <p>Return the single root pair.</p> RETURNS DESCRIPTION <code>Pair</code> <p>The first Pair in the sequence.</p>"},{"location":"api/#pest.Pairs.flatten","title":"flatten","text":"<pre><code>flatten() -&gt; Iterator[Pair]\n</code></pre> <p>Generate a flat iterator over all pairs and their descendants.</p>"},{"location":"api/#pest.Pairs.stream","title":"stream","text":"<pre><code>stream() -&gt; Stream\n</code></pre> <p>Return pairs as a stream that can be stepped through.</p>"},{"location":"api/#pest.Pairs.tokens","title":"tokens","text":"<pre><code>tokens() -&gt; Iterator[Token]\n</code></pre> <p>Yield start and end tokens for each pair in the sequence.</p>"},{"location":"api/#pest.PrattParser","title":"pest.PrattParser","text":"<p>               Bases: <code>ABC</code>, <code>Generic[ExprT]</code></p> <p>Generic Pratt parser base class operating on a pest <code>Stream</code> of <code>Pair</code>s.</p> <p>Subclasses define how to construct AST nodes by overriding the four abstract parse_* methods and providing operator-precedence tables.</p>"},{"location":"api/#pest.PrattParser.INFIX_OPS","title":"INFIX_OPS  <code>class-attribute</code>","text":"<pre><code>INFIX_OPS: dict[str, tuple[int, bool]] = {}\n</code></pre> <p>Mapping of infix operator rule names to (precedence, right_associative).</p>"},{"location":"api/#pest.PrattParser.LEFT_ASSOC","title":"LEFT_ASSOC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LEFT_ASSOC = False\n</code></pre> <p>An alias for <code>False</code>.</p> <p>Use it as the second item in <code>INFIX_OPS</code> values, right_associative, for improved readability.</p>"},{"location":"api/#pest.PrattParser.POSTFIX_OPS","title":"POSTFIX_OPS  <code>class-attribute</code>","text":"<pre><code>POSTFIX_OPS: dict[str, int] = {}\n</code></pre> <p>Mapping of postfix operator rule names to precedence levels.</p>"},{"location":"api/#pest.PrattParser.PREFIX_OPS","title":"PREFIX_OPS  <code>class-attribute</code>","text":"<pre><code>PREFIX_OPS: dict[str, int] = {}\n</code></pre> <p>Mapping of prefix operator rule names to precedence levels.</p>"},{"location":"api/#pest.PrattParser.RIGHT_ASSOC","title":"RIGHT_ASSOC  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RIGHT_ASSOC = True\n</code></pre> <p>An alias for <code>True</code>.</p> <p>Use it as the second item in <code>INFIX_OPS</code> values, right_associative, for improved readability.</p>"},{"location":"api/#pest.PrattParser.parse_expr","title":"parse_expr","text":"<pre><code>parse_expr(stream: Stream, min_prec: int = 0) -&gt; ExprT\n</code></pre> <p>Parse an expression from a pest <code>Stream</code> using Pratt precedence rules.</p>"},{"location":"api/#pest.PrattParser.parse_infix","title":"parse_infix  <code>abstractmethod</code>","text":"<pre><code>parse_infix(lhs: ExprT, op: Pair, rhs: ExprT) -&gt; ExprT\n</code></pre> <p>Build a node for an infix operator expression.</p>"},{"location":"api/#pest.PrattParser.parse_postfix","title":"parse_postfix  <code>abstractmethod</code>","text":"<pre><code>parse_postfix(lhs: ExprT, op: Pair) -&gt; ExprT\n</code></pre> <p>Build a node for a postfix operator expression.</p>"},{"location":"api/#pest.PrattParser.parse_prefix","title":"parse_prefix  <code>abstractmethod</code>","text":"<pre><code>parse_prefix(op: Pair, rhs: ExprT) -&gt; ExprT\n</code></pre> <p>Build a node for a prefix operator expression.</p>"},{"location":"api/#pest.PrattParser.parse_primary","title":"parse_primary  <code>abstractmethod</code>","text":"<pre><code>parse_primary(pair: Pair) -&gt; ExprT\n</code></pre> <p>Parse a primary expression: literal, variable, or parenthesized.</p>"},{"location":"api/#pest.Stream","title":"pest.Stream","text":"<p>Step through pairs of tokens.</p> <p>Provides a simple interface for sequential access to a list of Pair objects.</p>"},{"location":"api/#pest.Stream.backup","title":"backup","text":"<pre><code>backup() -&gt; None\n</code></pre> <p>Go back one position in the stream, if possible.</p>"},{"location":"api/#pest.Stream.next","title":"next","text":"<pre><code>next() -&gt; Pair | None\n</code></pre> <p>Return the next pair and advance the stream.</p> RETURNS DESCRIPTION <code>Pair | None</code> <p>The next Pair, or None if at the end of the stream.</p>"},{"location":"api/#pest.Stream.peek","title":"peek","text":"<pre><code>peek() -&gt; Pair | None\n</code></pre> <p>Return the next pair without advancing the stream.</p> RETURNS DESCRIPTION <code>Pair | None</code> <p>The next Pair, or None if at the end of the stream.</p>"},{"location":"api/#pest.Token","title":"pest.Token","text":"<p>User-facing token stream element (start or end of a rule).</p> PARAMETER DESCRIPTION <code>rule</code> <p>name of the matched rule.</p> <p> TYPE: <code>Rule | RuleFrame</code> </p> <code>pos</code> <p>start position in Unicode code points.</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/#pest.Start","title":"pest.Start","text":"<p>               Bases: <code>Token</code></p> <p>A token indicating the start of a rule.</p>"},{"location":"api/#pest.End","title":"pest.End","text":"<p>               Bases: <code>Token</code></p> <p>A token indicating the end of a rule.</p>"},{"location":"api/#pest.Position","title":"pest.Position","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A position in a string as a Unicode codepoint offset.</p> <p>Provides utilities for determining line and column numbers.</p>"},{"location":"api/#pest.Position.line_col","title":"line_col","text":"<pre><code>line_col() -&gt; tuple[int, int]\n</code></pre> <p>Return the line and column number of this position.</p> RETURNS DESCRIPTION <code>tuple[int, int]</code> <p>A tuple (line_number, column_number), both 1-based.</p>"},{"location":"api/#pest.Position.line_of","title":"line_of","text":"<pre><code>line_of() -&gt; str\n</code></pre> <p>Return the line of text that contains this position.</p>"},{"location":"api/#pest.Span","title":"pest.Span","text":"<p>               Bases: <code>NamedTuple</code></p> <p>A half-open interval [start, end) into the input string.</p> <p>Represents a substring of the input, along with its start and end positions.</p>"},{"location":"api/#pest.Span.as_str","title":"as_str","text":"<pre><code>as_str() -&gt; str\n</code></pre> <p>Return the slice of the source corresponding to this span.</p>"},{"location":"api/#pest.Span.end_pos","title":"end_pos","text":"<pre><code>end_pos() -&gt; Position\n</code></pre> <p>Return this span's end position.</p>"},{"location":"api/#pest.Span.lines","title":"lines","text":"<pre><code>lines() -&gt; list[str]\n</code></pre> <p>Return a list of lines covered by this span.</p> <p>Includes lines that are partially covered.</p>"},{"location":"api/#pest.Span.split","title":"split","text":"<pre><code>split() -&gt; tuple[Position, Position]\n</code></pre> <p>Return a tuple of start position and end position.</p>"},{"location":"api/#pest.Span.start_pos","title":"start_pos","text":"<pre><code>start_pos() -&gt; Position\n</code></pre> <p>Return this span's start position.</p>"},{"location":"api/#pest.Rule","title":"pest.Rule","text":"<p>               Bases: <code>Expression</code></p> <p>Base class for all rules.</p>"},{"location":"api/#pest.Rule.children","title":"children","text":"<pre><code>children() -&gt; list[Expression]\n</code></pre> <p>Return this expression's children.</p>"},{"location":"api/#pest.Rule.generate","title":"generate","text":"<pre><code>generate(\n    gen: Builder, matched_var: str, pairs_var: str\n) -&gt; None\n</code></pre> <p>Emit Python source code that implements this grammar expression.</p>"},{"location":"api/#pest.Rule.parse","title":"parse","text":"<pre><code>parse(state: ParserState, pairs: list[Pair]) -&gt; bool\n</code></pre> <p>Attempt to match this expression against the input at <code>start</code>.</p>"},{"location":"api/#pest.Rule.with_children","title":"with_children","text":"<pre><code>with_children(expressions: list[Expression]) -&gt; Self\n</code></pre> <p>Return a new instance of this expression with child expressions replaced.</p>"},{"location":"api/#pest.RuleFrame","title":"pest.RuleFrame","text":"<p>Rule meta data for the generated rule stack.</p> <p>Generated parser don't have access to complete <code>Rule</code> object. <code>RuleFrame</code> is a lightweight stand in.</p> ATTRIBUTE DESCRIPTION <code>name</code> <p>The rule's name.</p> <p> TYPE: <code>str</code> </p> <code>modifier</code> <p>A bit mask encoding modifiers applied to the rule.</p> <p> TYPE: <code>int</code> </p>"},{"location":"api/#pest.PestParsingError","title":"pest.PestParsingError","text":"<p>               Bases: <code>Exception</code></p> <p>An exception raised when an input string can't be passed by a pest grammar.</p>"},{"location":"api/#pest.PestParsingError.detailed_message","title":"detailed_message","text":"<pre><code>detailed_message() -&gt; str\n</code></pre> <p>Return an error message formatted with extra context info.</p>"},{"location":"api/#pest.PestParsingError.expected","title":"expected","text":"<pre><code>expected(\n    expected: dict[str, list[str]],\n    unexpected: dict[str, list[str]],\n) -&gt; str\n</code></pre> <p>Return the expected/unexpected part of a detailed error message.</p>"},{"location":"api/#pest.PestParsingError.expected_labels","title":"expected_labels","text":"<pre><code>expected_labels(\n    expected: dict[str, list[str]],\n    unexpected: dict[str, list[str]],\n) -&gt; str | None\n</code></pre> <p>Return a string representation of expected and unexpected labels.</p>"},{"location":"overview/","title":"Parsing with Python Pest","text":"<p>Python Pest is a port of the Rust Pest parsing library - a powerful, elegant PEG (Parsing Expression Grammar) parser generator.</p> <p>It brings the same expressive grammar syntax and predictable parsing model to Python, while preserving Pest's clean and declarative approach to grammar design.</p> <p>Python Pest uses exactly the same grammar syntax as Pest v2, so existing Pest grammars can be used without modification.</p> <p>It also provides a token pair API that closely mirrors Rust Pest's <code>Pair</code> and <code>Pairs</code> interfaces, making it immediately familiar to anyone who has used Pest in Rust.</p> <p>If you're new to Pest or PEG parsers, we highly recommend reading through the Pest Book. Even if you're not a Rust developer, the book provides an excellent introduction to the core ideas behind Pest's grammar syntax, parsing model, and design philosophy - all of which apply directly to Python Pest.</p> <p>Python Pest aims to feel native in Python while staying true to the spirit and strengths of the original Rust Pest library.</p>"},{"location":"overview/#conceptual-overview","title":"Conceptual overview","text":"<p>When writing a hand-crafted parser, we typically start with a lexer (also called a scanner or tokenizer). The lexer scans raw input text and produces a stream of tokens - symbolic representations of meaningful units like identifiers, keywords, or punctuation.</p> <p>A parser then consumes those tokens according to the language's grammar and constructs an abstract syntax tree (AST) or another intermediate structure.</p> <pre><code>Lexer -&gt; Tokens -&gt; Parser -&gt; AST ..\n</code></pre> <p>This approach gives you fine-grained control over every stage, but it also means you have to define both the tokenization and parsing logic by hand - including the rules, ordering, and tree construction.</p> <p>When using Pest, we instead start by writing a grammar using Pest's expressive PEG (Parsing Expression Grammar) syntax. Pest uses this grammar to automatically generate a parse tree from input text.</p> <p>Each non-silent rule in the grammar appears as a node in the parse tree, paired with its matched text. You can then traverse this tree to build your own AST or evaluate results directly.</p> <pre><code>Grammar -&gt; Parse Tree -&gt; Parser -&gt; AST ..\n</code></pre> <p>Compared to a hand-crafted parser, Pest's parse trees are more structurally rich. They mirror the hierarchy of your grammar rather than producing a flat stream of tokens. This makes it easier to reason about nesting, precedence, and composition.</p> <p>In short:</p> <ul> <li>Hand-crafted parsers require explicit control over lexing and parsing.</li> <li>Pest parsers let you define the grammar declaratively and focus on transforming the resulting structured tree into meaningful data.</li> </ul>"},{"location":"overview/#parse-trees-and-token-pairs","title":"Parse trees and token pairs","text":"<p>When you parse input with Python Pest, the result is a parse tree - a hierarchical representation of how your input text matched the grammar. Each node in this tree corresponds to a grammar rule that successfully matched part of the input.</p> <p>At the core of this structure is the <code>Pair</code> class. A <code>Pair</code> represents a pair of tokens: the start and end markers that delimit a substring of the original input. In other words, every <code>Pair</code> knows:</p> <ul> <li>which rule it matched (<code>pair.name</code> or <code>pair.rule.name</code>),</li> <li>the span of input text it covers (<code>pair.text</code> or <code>str(pair)</code>),</li> <li>and any nested rules it contains (<code>for child in pair:</code> or <code>pair.inner()</code>).</li> </ul> <p>This structure mirrors your grammar exactly. If a rule in your grammar contains other rules, those inner rules appear as child <code>Pair</code> objects within the parent. Together, these pairs form the parse tree, which captures both the structure and meaning of your input.</p> <p>For example, using the calculator grammar in <code>examples/calculator/grammar_encoded_prec.pest</code>, the input <code>2 * 3 + 4</code> produces a parse tree like this:</p> <pre><code>- program\n  - expr &gt; add_sub\n    - mul_div\n      - pow_expr &gt; prefix &gt; postfix &gt; int: \"2\"\n      - mul: \"*\"\n      - pow_expr &gt; prefix &gt; postfix &gt; int: \"3\"\n    - add: \"+\"\n    - mul_div &gt; pow_expr &gt; prefix &gt; postfix &gt; int: \"4\"\n  - EOI: \"\"\n</code></pre> <p>Notice that <code>2 * 3</code> is nested deeper than <code>+ 4</code>, encoding the fact that multiplication has higher precedence that addition.</p> <p>In practice, you'll typically walk the parse tree to transform it into a more useful data structure, such as an abstract syntax tree (AST) or a Python object model.</p>"},{"location":"overview/#destructuring-token-pairs","title":"Destructuring token pairs","text":"<p>Python Pest\u2019s Pair class defines <code>__match_args__</code>:</p> <pre><code>__match_args__ = (\"name\", \"children\")\n</code></pre> <p>This makes <code>Pair</code> objects integrate seamlessly with Python's structural pattern matching (<code>match</code>/<code>case</code>). You can destructure pairs directly by their rule name and child structure, making parse tree traversal both concise and expressive. This example comes from <code>examples/jsonpath/jsonpath.py</code>.</p> <pre><code>def parse_segment(self, segment: Pair) -&gt; Segment:\n    match segment:\n        case Pair(Rule.CHILD_SEGMENT, [inner]):\n            return ChildSegment(segment, self.parse_segment_inner(inner))\n        case Pair(Rule.DESCENDANT_SEGMENT, [inner]):\n            return RecursiveDescentSegment(segment, self.parse_segment_inner(inner))\n        case Pair(Rule.NAME_SEGMENT, [inner]) | Pair(Rule.INDEX_SEGMENT, [inner]):\n            return ChildSegment(segment, [self.parse_selector(inner)])\n        case _:\n            raise JSONPathSyntaxError(\"expected a segment\", segment)\n</code></pre>"},{"location":"overview/#grammar-syntax-quick-reference","title":"Grammar syntax quick reference","text":"<p>For a complete explanation of grammar syntax see the official Pest Book.</p>"},{"location":"overview/#grammar-rule","title":"Grammar rule","text":"syntax<pre><code>rule = { ... }\n</code></pre> <p>Defines a standard grammar rule. Rules can refer to other rules by name.</p> example<pre><code>ident = { ASCII_ALPHA+ }\n</code></pre> <p><code>ASCII_ALPHA</code> is a built-in rule. See the Pest book for a complete list of built-in rules.</p>"},{"location":"overview/#silent-rule","title":"Silent rule","text":"syntax<pre><code>rule = _{ ... }\n</code></pre> <p>A silent rule matches input but does not appear in the parse tree. <code>WHITESPACE</code> is a special rule. If defined, it enables implicit whitespace between items in a sequence and when repeating expressions.</p> example<pre><code>WHITESPACE = _{ \" \" }\n</code></pre>"},{"location":"overview/#atomic-rule","title":"Atomic rule","text":"syntax<pre><code>rule = _{ ... }\n</code></pre> <p>An atomic rule disables implicit whitespace and hides all inner rules, producing a single leaf node in the parse tree.</p> example<pre><code>int = @{ ASCII_DIGIT+ }\n</code></pre>"},{"location":"overview/#compound-atomic-rule","title":"Compound atomic rule","text":"syntax<pre><code>rule = ${ ... }\n</code></pre> <p>A compound atomic rule disables implicit whitespace but keeps inner rules visible in the parse tree.</p> example<pre><code>full_time = ${ partial_time ~ time_offset }\n</code></pre>"},{"location":"overview/#non-atomic-rule","title":"Non-atomic rule","text":"syntax<pre><code>rule = !{ ... }\n</code></pre> <p>Cancels atomicity if called from an atomic parent rule.</p> example<pre><code>expr = !{ term ~ (\"+\" ~ term)* }\n</code></pre>"},{"location":"overview/#string-literal","title":"String literal","text":"syntax<pre><code>\"...\"\n</code></pre> <p>Matches an exact string, case-sensitively. String literals can contain escape sequences including Unicode escapes.</p> example<pre><code>\"let\"\n</code></pre>"},{"location":"overview/#case-insensitive-string","title":"Case-insensitive string","text":"syntax<pre><code>^\"...\"\n</code></pre> <p>Matches a string, case-insensitively.</p> example<pre><code>^\"select\"\n</code></pre>"},{"location":"overview/#character-range","title":"Character range","text":"syntax<pre><code>'a'..'z'\n</code></pre> <p>Matches any character within the specified inclusive range. Unicode escapes are supported.</p> example<pre><code>'\\u{80}'..'\\u{D7FF}'\n</code></pre>"},{"location":"overview/#any-character","title":"Any character","text":"syntax<pre><code>ANY\n</code></pre> <p>Matches any single character.</p>"},{"location":"overview/#sequence","title":"Sequence","text":"syntax<pre><code>A ~ B\n</code></pre> <p>Matches A followed by B, with implicit whitespace between them if the special <code>WHITESPACE</code> rule is defined, unless inside an atomic context.</p> example<pre><code>\"[\" ~ int_list ~ \"]\"\n</code></pre>"},{"location":"overview/#ordered-choice","title":"Ordered choice","text":"syntax<pre><code>A | B\n</code></pre> <p>Matches A or B, choosing the first successful alternative. PEG grammars are deterministic - once a branch succeeds, the others are not tried.</p> example<pre><code>\"a\" | \"b\"\n</code></pre>"},{"location":"overview/#grouping","title":"Grouping","text":"syntax<pre><code>( ... )\n</code></pre> <p>Groups expressions and controls operator precedence.</p> example<pre><code>( A | B )*\n</code></pre>"},{"location":"overview/#repetition","title":"Repetition","text":"syntax<pre><code>*\n+\n?\n{n}\n{m,n}\n</code></pre> <p>Control how many times a pattern repeats:</p> <ul> <li><code>*</code> - zero or more</li> <li><code>+</code> - one or more</li> <li><code>?</code> - optional (zero or one)</li> <li><code>{n}</code> - exactly n times</li> <li><code>{m,n}</code> - between m and n times (inclusive). Either <code>m</code> or <code>n</code> can be omitted.</li> </ul> examples<pre><code>ASCII_DIGIT*\nASCII_DIGIT+\n\"-\"?\nASCII_HEX_DIGIT{2}\nhex_digit{2, 6}\n</code></pre>"},{"location":"overview/#positive-predicate","title":"Positive predicate","text":"syntax<pre><code>&amp;A\n</code></pre> <p>Positive lookahead succeeds if <code>A</code> matches but does not consume input.</p> example<pre><code>ident ~ &amp;\"=\"\n</code></pre>"},{"location":"overview/#negative-predicate","title":"Negative predicate","text":"syntax<pre><code>!A\n</code></pre> <p>Negative lookahead succeeds if <code>A</code> does not match.</p> example<pre><code>literal ~ !\"=\"\n</code></pre>"},{"location":"overview/#stack-operations","title":"Stack operations","text":"syntax<pre><code>PUSH(expr)\nPUSH_LITERAL(\"...\")\nPOP\nPEEK\nPEEK[..]\nDROP\nPEEK_ALL\n</code></pre> <p>Pest provides a stack for stateful parsing.</p> <ul> <li><code>PUSH(expr)</code> - Match <code>expr</code> and push the matched string onto the stack</li> <li><code>PUSH_LITERAL(\"...\")</code> - Push a string literal onto the stack. Never fails.</li> <li><code>POP</code> - Remove and match the value at the top of the stack.</li> <li><code>PEEK</code> - Match the value on the top oof the stack without removing it.</li> <li><code>PEEK</code> - Match a slice of the stack from bottom to top.</li> <li><code>DROP</code> - Pop from the stack without matching. Fails if the stack is empty.</li> <li><code>PEEK_ALL</code> - Match all items from the stack from top to bottom.</li> </ul> examples<pre><code>PUSH(A)\nPUSS(\"a\")\nPOP\nPEEK\nPEEK[1..3]\nDROP\nPEEK_ALL\n</code></pre>"},{"location":"overview/#tags","title":"Tags","text":"syntax<pre><code>#tag=A\n</code></pre> <p>Tags label expressions for later reference or tooling. Tags are always enabled in Python Pest.</p> example<pre><code>#literal = hex_digit{2, 6}\n</code></pre>"}]}